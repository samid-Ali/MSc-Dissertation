---
title: "The Macroeconomic Effects of Fiscal Adjusments in The UK "
author: "Samid Ali"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
    citation_package: biblatex
bibliography: references.bib
csl: harvard-kings-college-london.csl
documentclass: article
header-includes:
  - \usepackage{biblatex}
  - \addbibresource{references.bib}
---

```{r setup, include=FALSE}


# library(knitr)
# library(stargazer)
# library(clipr)
#library(kableExtra) 

library(ggplot2)
library(knitr)
library(ivreg)
library(ggdag)
library(data.table)
library(dplyr)
library(tidyr)
library(stargazer)
library(clipr)
library(tibble)
library(lubridate)
# install.packages("seasonal")
library(seasonal)



lapply(c("ggplot2", "dplyr", "data.table", "lubridate", "janitor", "broom", "tibble", "tidyr", "aTSA", "vars"),
       require, character.only = TRUE)

# knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)



```



\newpage

# Abstract

# Introduction


# Literature Review


## Costs of high indebtedness

@sutherland2012 draw attention to the fiscal challenges facing countries following the Global Financial Crisis, noting that gross government debt has exceeded 100% of GDP for the OECD as an aggregate. This has been exacerbated following the Covid pandemic where governments implemented fiscal measures to mitigate the economic costs of the pandemic. Makin and Layton (2021) highlight that governments must employ fiscal responsibility to protect their economies from the risks that high indebtedness exposes them to. @warmedinger2015 emphasise the importance of public debt sustainability for ensuring macroeconomic stability. There are several mechanisms through which excessive debt could harm the economy. For instance, concerns regarding public finances could reduce business confidence, leading to decreased investment and thus a slowdown in growth. Additionally, strained public finances could hinder the ability of economies to react counter cyclically to economic shocks. This rationale is supported by the IMF (2023) who argue that economies should rebuild their fiscal buffers to reduce their debt vulnerabilities. Therefore, fiscal consolidation is clearly needed to ensure the long-term resilience of the economy. As a target, @sutherland2012 propose that countries should aim to bring debt levels towards 50% of GDP: a figure which would require the UK to halve its current debt levels (ONS, 2025). The IMF (2023) argues that to stabilise GDP, fiscal adjustments should be in the region of up to 4% of GDP. Thus, achieving this objective would require significant fiscal adjustments, motivating further research to support the transition towards more sustainable public finances. Alesina, Favero, and Giavazzi (2012) find that permanent fiscal adjustments have lower output costs, interpreting this result as due to business confidence. (easier to forecast when fiscal adjustments are more predictable? Thus have less of a effect on confidence) 


Kumar and Woo (2015) find that greater indebtedness is associated with lower economic growth. They also find noticeable nonlinearities in this result, with the most severe effect when public indebtedness exceeds 90% of GDP. Given the aforementioned level of public indebtedness in the UK ...  
Blanchard (2019) argue that even when the interest rate is less than the growth rate, and thus there is no fiscal cost of high indebtedness, there may still be a welfare cost due to reduced capital accumulation.




## Fiscal Consolidaton

While the importance of fiscal consolidation has been highlighted, it is crucial that these measures are not at the expense of the broader economy. By investigating forecast errors for a sample of European countries, @blanchard2013 find that larger anticipated fiscal consolidation was associated with lower growth. This result was interpreted as due to the fiscal multiplier being greater than anticipated by forecasters. Consequently, fiscal tightening would have further dampened demand, and thus improvements in fiscal consolidation would be offset by reduced growth. Gechert (2019) adopt a similar methodology, finding that austerity measures in the Euro Area deepened the crisis, contributing to hysterisis effects. 
Fatas and Summers (2018) extend this research, investigating the long-term effects that fiscal adjustments have had on GDP. Their analysis suggests that fiscal consolidations have failed to lower the debt-to-GDP ratio due to a hysteresis effect of contractionary fiscal policy. This research underscores the need for effectively quantifying fiscal multipliers to understand potential trade-offs between various economic objectives. @ilzetzki2013 provide further insight into the fiscal multiplier, suggesting that the heterogeneity in the estimates reported in the literature can be attributed to differences in structural characteristics of the economy considered. This reinforces the importance of research to better understand the fiscal multiplier for different policy instruments, particularly as this may vary across countries and over time. Additionally, Alesina et al (2015) compare multipliers due to spending and tax adjustments. They find that ... have more severe effects, attributing this to reduced business confidence. Alesina et al (2002) investigate the effect of fiscal policy on investment. 

## Synthesis of Methodology

Capek and Cuasera (2020) simulate 20 million fiscal multipliers, highlighting how methodological choices contribute to the heterogeneity in estimates of fiscal multipliers prevalent in the literature. Consequently, they advocate for explicitly outlining modelling choices and assumptions. Similarly, Gechert (2017) provides a synthesis of the methodologies used to estimate fiscal multipliers, highlighting competing definitions for the fiscal multiplier and possible issues in its estimation. Among these issues, Gechert (2017) highlight potential omitted variable bias in the VAR model (motivating the use of additional controls such as the price level and real interest rate), anticipation effects (cf Leepper + Zha fiscal foresight), and nonlinearities.

Structural Vector Autoregressions (SVARs) have been prominent in the literature to estimate fiscal multipliers. Various approaches to identification have been used, with XXX (YYYY) noting that after accounting for the empirical specification, the competing identifying approaches have little effect on the estimated multipliers. Blanchard and Perotti (2002) pioneered this strand of the research, leveraging methodologies previously popularised by the monetary economics. To identify their SVAR, Blanchard and Perotti leverage instituional information. They provide a definition for the fiscal variables and highlight that government expenditure is predetermined within a quarter. 
Recursive measures to identfication have been employed by Fatas and Mihov (YYYY) and Fernandex (2008). Fernandez argues that
Uhlig and Mountford (200Y) apply restrictions on the signs of the impulse response functions. 
Caldara and Kamps (2008) reviews the literature on SVAR identification. Caldara and Kamps (2017) introduce a new approach for identification.







```{r dataProc}

df <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/GDP.csv", skip = 1)


# Filter the data frame to exclude rows where the column 'title' matches any of the specified values


filtered_df <- df %>%
  # Keep only the quarterly data
  filter(nchar(CDID) == 7 & substr(CDID, 6, 6) == "Q") %>%
  # Select relevant columns and rename them
  dplyr::select(CDID, Deflator = L8GG, GDP = ABMI) %>%
  # Create new columns and convert types
  mutate(
    Year = as.numeric(substr(CDID, 1, 4)),
    Quarter = substr(CDID, 6, 7),
    Q = as.numeric(substr(CDID, 7, 7)),
    Deflator = as.numeric(Deflator),
    GDP = as.numeric(GDP)
  ) %>%
  # Filter by year (can modify for testing)
  filter(Year >= 1987)



fiscal_raw <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/Fiscal Data.csv", skip = 1)

fiscal_proc <- fiscal_raw %>% 
  dplyr::select(Date_ID = Transaction, Revenue = OTR, Expenditure = OTE) %>% 
  subset(Date_ID !=  "Dataset identifier code" & Date_ID != "Identifier") %>% 
  mutate(Year = as.numeric(gsub("\\D", "", Date_ID)),
         Period = gsub("\\d{4}", "", Date_ID))  %>% 
  mutate(
    Q = case_when(
      Period == "Jan to Mar " ~ 1,
      Period == "Apr to Jun " ~ 2,
      Period == "Jul to Sep " ~ 3,
      Period == "Oct to Dec " ~ 4
      ),
    Unique_Period = Year +(Q/4)
   
  ) %>% 
  # Convert to numeric and multiply by 1 million so values as these will later be made into per capita terms
  mutate(Revenue = as.numeric(gsub(",", "", Revenue) ),
         Expenditure = as.numeric(gsub(",", "", Expenditure )))

# join GDP deflator and GDP data

population <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/Population.csv", 
                    skip = 4, 
                    header = TRUE) %>% 
  subset(`Country Name` == "United Kingdom") %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "Year") %>% 
  rename(Population = V1 ) %>% 
  filter(grepl("^\\d{4}$", Year)) %>% 
  mutate(Year = as.numeric(Year),
         Population = as.numeric(Population))

Interest_SR <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/3 month Rate.csv") %>% 
  mutate(Date = dmy(Date),
         month = month(Date),
         Year = year(Date),
         Q = case_when(
           month %in% 1:3 ~ 1,
           month %in% 4:6 ~ 2,
           month %in% 7:9 ~ 3,
           month %in% 10:12 ~ 4
         )) %>% 
  group_by(Year, Q) %>% 
  summarize(mean_SR_Rate = mean(Rate, na.rm = TRUE))



SONIA <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/Bank of England  Database.csv") %>% 
  mutate(Date = dmy(Date),
         month = month(Date),
         Year = year(Date),
         Q = case_when(
           month %in% 1:3 ~ 1,
           month %in% 4:6 ~ 2,
           month %in% 7:9 ~ 3,
           month %in% 10:12 ~ 4
         )) %>% 
  group_by(Year, Q) %>% 
  summarize(mean_SONIA = mean(SONIA, na.rm = TRUE))

Policy_Rate <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/Policy Rate.csv") %>%
  mutate(Date = parse_date_time(`Date Changed`, orders = "dmy"),
         Q = quarter(Date),
         Year = year(Date)) %>%
  group_by(Year, Q) %>%
  summarise(mean_SR_Rate = mean(Rate, na.rm = TRUE), .groups = "drop") %>%
  complete(Year = full_seq(Year, 1), Q = 1:4) %>%  # Ensure all Year-Quarter combinations
  arrange(Year, Q) %>%
  fill(mean_SR_Rate, .direction = "down")  # Fill missing rates by propagating the previous value

Exports <- fread("D:/Samid work/University/KCL - Econ and Policy/Dissertation/Data/Exports.csv") %>% 
  mutate(Date = dmy(Month),
         month = month(Month),
         Year = year(dmy(Month)),
         Q = case_when(
           month %in% 1:3 ~ 1,
           month %in% 4:6 ~ 2,
           month %in% 7:9 ~ 3,
           month %in% 10:12 ~ 4
         )) %>% 
  group_by(Year, Q) %>% 
  summarize(Exports = sum(Exports, na.rm = TRUE))


data <- fiscal_proc %>% 
  left_join(filtered_df, by = c("Q" = "Q", "Year" = "Year")) %>% 
  left_join(Interest_SR, by = c("Q" = "Q", "Year" = "Year")) %>% 
  left_join(Exports, by = c("Q" = "Q", "Year" = "Year")) %>% 
  left_join(population, by = c("Year" = "Year")) %>% 
# Convert variables to per capita, note revenue, expenditure, and GDP are in £ million so need to multiply. Doing this
  mutate(RevenuePerCapita = (Revenue *10^6) /Population,
         ExpenditurePerCapita = (Expenditure *10^6) /Population,
         GDPPerCapita = (GDP *10^6) /Population) %>% 
  
  # Seasonal Adjustment of data using X-13ARIMA-SEATS
   mutate(Revenue_SA = final(seas(ts(Revenue, start = min(Year), frequency = 4))),
         Expenditure_SA = final(seas(ts(Expenditure, start = min(Year), frequency = 4))),
         GDP_SA = final(seas(ts(GDP, start = min(Year), frequency = 4)))) %>% 

# Convert variables (except interest rate) to logs
  mutate(log_revenue = log(Revenue_SA *10^6),
         log_expenditure = log(Expenditure_SA *10^6),
         log_GDP = log(GDP_SA *10^6),
         log_deflator = log(Deflator),
         log_exports = log(Exports))

         
model_data <- data %>% 
  dplyr::select(CDID, log_expenditure, mean_SR_Rate, log_exports, log_GDP, log_revenue,  log_deflator)


  


```
# Plots


```{r Seasonal Adjsutment Plot}

# plot(seas(ts(data$Expenditure, start = min(data$Year), frequency = 4)))
plot(seas(ts(data$Revenue, start = min(data$Year), frequency = 4)))




```


```{r Unfiltered Fiscal TS}

ggplot(data, aes(x = Unique_Period)) +
  geom_line(aes(y = Revenue, color = "Revenue"), size = 1) +
  geom_line(aes(y = Expenditure, color = "Expenditure"), size = 1) +
  labs(
    x = "Date ID",
    y = "Amount (? in millions)",
    title = "Revenue and Expenditure Over Time",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Revenue" = "blue", "Expenditure" = "red")) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  )


```



```{r Seasonally Adjusted Fiscal TS}

ggplot(data, aes(x = Unique_Period)) +
  geom_line(aes(y = Revenue_SA, color = "Revenue"), size = 1) +
  geom_line(aes(y = Expenditure_SA, color = "Expenditure"), size = 1) +
  labs(
    x = "Date ID",
    y = "Amount (? in millions)",
    title = "Seasonally Adjusted Revenue and Expenditure Over Time",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Revenue" = "blue", "Expenditure" = "red")) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  )


```


```{r Exports TS}

ggplot(data, aes(x = Unique_Period)) +
  geom_line(aes(y = Exports, color = "Exports"), size = 1) +
  labs(
    x = "Date ID",
    y = "Amount (? in millions)",
    title = "Exports Over Time",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Exports" = "red")) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  )


```

```{r GDP}

# Define scaling factor based on range ratios
scale_factor <- max(data$Deflator, na.rm = TRUE) / max(data$mean_SR_Rate, na.rm = TRUE)

ggplot(data, aes(x = Unique_Period)) +
  geom_line(aes(y = Deflator, color = "Deflator"), size = 1) +
  geom_line(aes(y = mean_SR_Rate * scale_factor, color = "Mean SR Rate"), size = 1, linetype = "dashed") +
  scale_y_continuous(
    name = "Amount ",
    sec.axis = sec_axis(~ . / scale_factor, name = "Mean SR Rate (%)")
  ) +
  labs(
    x = "Date ID",
    title = "Deflator and Mean SR Rate Over Time",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Deflator" = "blue", "Mean SR Rate" = "Red")) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  )
```

```{r Deflator}

ggplot(data, aes(x = Unique_Period)) +
  geom_line(aes(y = Deflator, color = "Deflator"), size = 1) +
  labs(
    x = "Date ID",
    y = "Amount (? in millions)",
    title = "Revenue and Expenditure Over Time",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Deflator" = "blue", "Expenditure" = "red")) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  )


```



```{r  }


```



```{r Stationarity Testing}




```





# Econometric Methodology

This section outlines the VAR methodology that will be employed by this research. The reduced-form VAR model can be written as:

\[
X_t = \mu +  A_1 X_{t-1} + A_2 X_{t-2} + \cdots + X_p Y_{t-p} + \epsilon_t
\]



where \( \epsilon_t \) is the vector of reduced-form residuals and $p$ determines the lag length. In line with XXX we assume the model contains 4 lags. Given the use of quarterly data, this can be interpreted as lags of the model variables having a direct affect for up to a year. This use of lag is supported by the Akaike Information Criteria. The VAR model above assumes that the data generating process includes a deterministic linear time trend and constant intercept. This is included to mitigate for potential spurious regression between trending factors in the deflator rate and other variables in the system.

Regarding the endogenous variables considered, Blanchard and Perotti (2002) investigate the effects of fiscal shocks using a three-dimensional vector autoregressive model consisting of GDP, government expenditure, and governemnet revenue. While such a model could be used to estimate the effects of fiscal shocks, Gechert (2017) highlights the potential issues of omitted variable bias. Consequently we augment the 
model to include also a short term interest rate, the GDP deflator rate, and UK exports. These variables are included to account for the effects of monetary policy, price levels, and trade respectively.

The data is used at a quarterly frequency from 1987:1 to 2023:3. The fiscal variables are defined at the general level and follow the European System of Accounts (ESA, 2010). In particular, government expenditure represents the outflows associated with government activities, including consumption, investment, and transfers. The inflows to the government, government revenue, consists of receipts net of transfer and interest payments. Cf Blanchard and Perotti (2002).

Following Fernandez (2006), the natural logarithm of these variables is used, with the exception of the short term interest rate, which enters the model in levels. Furthermore, the fiscal variables and GDP are used in real terms. Capek and Cuaresma (2020) highlight that data used to estimate fiscal multipliers is typically seasonally adjusted. Therefore (with the exception of GDP which was sourced after seasonal adjustment) variables have been seasonally adjusted using X-13ARIMA-SEATS method. 
The intention of this is tease out the noise from the data so that the model can estimate the underlying trends. The model includes a trend component to account for ... Gechert (2017) highlight the importance of  

- debt sustainability


\[
X_t = \begin{pmatrix} G_t \\ R_t \\ GDP_t \\ \tau_t \\ P_t \end{pmatrix}
\]


Discuss Empirical model, lag structure, data sources, potentially features of the data

## Data  Sources
- Fiscal Variables (not seasonally adjusted):  
https://www.ons.gov.uk/economy/governmentpublicsectorandtaxes/publicspending/datasets/esatable25quarterlynonfinancialaccountsofgeneralgovernment
- UK Exports (seasonally Adjusted, %):  
https://fred.stlouisfed.org/series/XTEXVA01GBQ188S
- LFS (Pop aged 16-64):  
https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/timeseries/lf2o/lms
- GDP (SA) and defaltor rate:  
https://www.ons.gov.uk/economy/grossdomesticproductgdp/bulletins/quarterlynationalaccounts/latest#data-on-gdp-quarterly-national-accounts
- interest rate (SR. This is dates of changes to the policy rate. Have interpolated to get quarterly data):  
https://www.bankofengland.co.uk/monetary-policy/the-interest-rate-bank-rate
- 3 month interest rate:  
https://fred.stlouisfed.org/series/IR3TIB01GBM156N



```{r Bivariate - Optimal Lags}

clean_data <- na.omit(model_data)

tmp <- clean_data[,-1]

OptimalLag <-  VARselect(clean_data[,-c(1)], lag.max = 5, type = "both")
OptimalLag$selection
# OptimalLag$criteria

```



```{r ReducedVAR}
# library(vars)

reduced_VAR <- VAR(clean_data[, -1], p = 4, type = "both")
# reduced_VAR <- VAR(clean_data[, -1], p = 4)

# summary(reduced_VAR)

# Summary reports the roots of the polynomial. 
     
```
Note: VAR analysis requires stability of the system. Need to find code to ensure the eigenvalues of the autoregressive roots lie within the unit circle.

```{r, stability_eigenvalues}

roots(reduced_VAR)


```


# Identification

Explaining distinction between the reduced form and structural model. Interested in the structural shocks which we will recover as follows.


Let \( X_t \) be the vector of variables:

\[ X_t = \begin{pmatrix} G_t \\ R_t \\ GDP_t \\ T_t \\ P_t \end{pmatrix} \]

The reduced-form VAR model can be written as:

\[ X_t = A_1 X_{t-1} + A_2 X_{t-2} + \cdots + A_p X_{t-p} + \epsilon_t \]

where \( \epsilon_t \) is the vector of reduced-form residuals. To recover the structural shocks \( u_t \), we assume:

\[ \epsilon_t = B u_t \]

$B^-1$ is the structural impact multiplier matrix. 

where \( B \) is a lower triangular matrix. The structural shocks \( u_t \) are assumed to be uncorrelated and have unit variance.

The matrix \( B \) can be obtained using Cholesky decomposition of the covariance matrix of the reduced-form residuals \( \Sigma_\epsilon \):

\[ \Sigma_\epsilon = E[\epsilon_t \epsilon_t'] = BB' \]

Given the recursive ordering \( (G, R, GDP, T, P) \), the matrix \( B \) has the form:

\[ B = \begin{pmatrix} 
b_{11} & 0 & 0 & 0 & 0 \\ 
b_{21} & b_{22} & 0 & 0 & 0 \\ 
b_{31} & b_{32} & b_{33} & 0 & 0 \\ 
b_{41} & b_{42} & b_{43} & b_{44} & 0 \\ 
b_{51} & b_{52} & b_{53} & b_{54} & b_{55} 
\end{pmatrix} \]

Thus, the structural shocks \( u_t \) can be recovered as:

\[ u_t = B^{-1} \epsilon_t \]




Killian and Lutkepohl (2017) highlight that identification of the structural parameters is not a purely statistical concern, the restrictions must also be economically meaningful for the resulting structural parameters to be identified. Therefore we proceed with an exposition of the economic assumptions implicit in the impact multiplier matrix, $B$, comparable to Fernandez (2006). 
1) Blanchard and Perotti (2002) argue that the use of quarterly data allows government spending to be interpreted as predetermined with respect to the rest of the variables within the quarter, consequently this is ordered first. 
2) Given physical constraints, the interest rate is assumed not to react contemporaneously to price, net taxes, or output.  
3) However monetary policy shocks are assumed to affect output, net taxes, and prices contemporaneously. Fernandez (2006) justifies this assumptions by noting that interest movements are anticipated and thus they can be transmitted to real variables relatively quickly. 
*NB on the appropriateness of the assumption that interest rate does not react to price/ output.*
4) Due to price stickiness, prices do not react contemporaneously to shocks to GDP, 
5) Due to physical constraints in adjusting consumption and investment, net taxes are assumed not to affect economic activity.  



```{r structural_VAR}

# Define the 5 dimensional lower triangular matrix, A

# Recover structural VAR using Cholesky decomposition

# Amat <- matrix(c(1, 0, 0, 0, 0,   # Recursive ordering
#                  NA, 1, 0, 0, 0,  
#                  NA, NA, 1, 0, 0,  
#                  NA, NA, NA, 1, 0,  
#                  NA, NA, NA, NA, 1), 
#                nrow = 5, byrow = TRUE)


Amat <- matrix(c(1, 0, 0, 0, 0, 0,   # Recursive ordering
                 NA, 1, 0, 0, 0, 0,  
                 NA, NA, 1, 0, 0, 0, 
                 NA, NA, NA, 1, 0, 0,  
                 NA, NA, NA, NA, 1, 0,
                 NA, NA, NA, NA, NA, 1), 
               nrow = 6, byrow = TRUE)



svar_model <- SVAR(reduced_VAR, Amat = Amat, estmethod = "direct")
# ?SVAR()

structural_shocks <- residuals(svar_model)

svar_model

irf_result <- irf(svar_model, n.ahead = 10, ci = 0.9, boot = 5000, cumulative = FALSE)  # Forecast horizons
# plot(irf_result)
# Visualize IRFs

FEVD_result <- fevd(svar_model, n.ahead = 10)  # Forecast horizons
plot(FEVD_result)

```



```{r, IRFs}
# Extract the first and second parts of the variable name
# Convert IRF results to data frames
irf_data <- as.data.frame(irf_result$irf)
irf_lower <- as.data.frame(irf_result$Lower)
irf_upper <- as.data.frame(irf_result$Upper)

# Add a time index to align data
irf_data$Time <- seq_len(nrow(irf_data))
irf_lower$Time <- irf_data$Time
irf_upper$Time <- irf_data$Time

# Reshape data for structured plotting
irf_long <- tidyr::pivot_longer(irf_data, cols = -Time, names_to = "Variable", values_to = "IRF")
lower_long <- tidyr::pivot_longer(irf_lower, cols = -Time, names_to = "Variable", values_to = "Lower")
upper_long <- tidyr::pivot_longer(irf_upper, cols = -Time, names_to = "Variable", values_to = "Upper")

# Merge confidence bounds into IRF dataset
irf_long <- irf_long %>%
  dplyr::left_join(lower_long, by = c("Time", "Variable")) %>%
  dplyr::left_join(upper_long, by = c("Time", "Variable")) %>%
  mutate(Shock = sub("\\..*", "", Variable),  # Extract part before dot
         Affected_Var = sub(".*\\.", "", Variable))  # Extract part after dot




shock_names <- unique(irf_long$Shock)
#
for (shock in shock_names) {
  p <- ggplot(irf_long %>% filter(Shock == shock), aes(x = Time, y = IRF)) +
    geom_line(size = 1, color = "blue") +  # Keep all lines the same color
    geom_line(aes(y = Lower), linetype = "dashed", color = "gray") +
    geom_line(aes(y = Upper), linetype = "dashed", color = "gray") +
    geom_hline(yintercept = 0, color = "black", size = 1) +  # Thick black x-axis line at y = 0
    facet_wrap(~ Affected_Var, scales = "free_y") +  # Create facets for affected variables
    theme_minimal() +
    labs(title = paste("Impulse Response for Shock:", shock),
         x = "Time",
         y = "Response")

  print(p)  # Print each figure separately
}

```



```{r Residuals}



FEVD_result
```

```{r, IRFs1}



# structural_shocks <- residuals(svar_model)
# irf_result <- irf(svar_model, n.ahead = 10)  # Forecast horizons
# plot(irf_result)  # Visualize IRFs


```

```{r, FEVD}

normality.test(reduced_VAR)



```





# Results

Ramey (2019) define fiscal multipliers: "change in output due to a change in spending or taxes", and highlight the risk of ignoring fiscal foresight. 
Gechert (2017)

# Robustness

# Discussion/ Policy Implications

# Conclusion

# Bibliography

\printbibliography


# Technical Appendix 
```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```

